# 面部表情识别功能使用指南

本文档提供了面试系统中面部表情识别功能的完整使用说明。

## 功能介绍

面部表情识别功能可以分析面试过程中的视频，自动检测并分析面部表情，提供情绪分析结果。系统会在视频的三个关键时间点（开始、中间、结束）提取帧，并分析每个帧中的面部表情，给出七种基本情绪的分布：

- 生气 (angry)
- 厌恶 (disgust)
- 恐惧 (fear)
- 开心 (happy)
- 中性 (neutral)
- 悲伤 (sad)
- 惊讶 (surprise)

## 安装依赖

在使用面部表情识别功能前，需要安装以下依赖：

```bash
pip install fer opencv-python numpy moviepy
```

或者使用我们提供的安装脚本：

```bash
python 视频和语音/install_all_dependencies.py
```

## 故障排除

如果遇到"面部表情识别功能不可用"的提示，可以尝试以下步骤：

1. **运行诊断脚本**：

```bash
python 视频和语音/diagnose_face_emotion.py
```

该脚本会检查依赖是否正确安装，并提供详细的问题排查建议。

2. **手动安装依赖**：

```bash
pip install fer opencv-python numpy moviepy
```

3. **使用模拟面部表情分析器**：

如果仍然无法安装FER库，可以使用模拟分析器代替：

```bash
python -c "import shutil; shutil.copy('视频和语音/mock_face_emotion_analyzer.py', '视频和语音/face_emotion_analyzer.py')"
```

模拟分析器不会进行实际的面部表情分析，但会提供模拟数据，使系统其他部分能够正常工作。

4. **测试表情识别功能**：

```bash
python 视频和语音/test_face_emotion.py [视频文件路径]
```

这个脚本会单独测试面部表情识别功能，便于排查问题。

## 从1111.py迁移

如果您之前使用了`面部识别/yolov12面部检测/1111.py`，我们的实现已经集成了该文件的核心功能，并进行了以下优化：

1. 更好的错误处理和回退机制
2. 模拟分析器支持，确保系统在FER库不可用时仍能工作
3. 与面试系统无缝集成

## 面部表情分析结果说明

分析结果会保存为文本文件，包含以下信息：

- 视频基本信息（总帧数、时长）
- 每个分析点的情绪分布
- 主要表情

示例结果：

```
=== 开始阶段 ===
帧号: 30
时间点: 1.00秒
主要表情: neutral
详细情绪分布:
  中性: 0.8532
  开心: 0.1245
  悲伤: 0.0223

=== 中间阶段 ===
帧号: 60
时间点: 2.00秒
主要表情: happy
详细情绪分布:
  开心: 0.6721
  中性: 0.3121
  惊讶: 0.0158

=== 结束阶段 ===
帧号: 90
时间点: 3.00秒
主要表情: neutral
详细情绪分布:
  中性: 0.7845
  开心: 0.2155
```

## 注意事项

1. FER库在第一次使用时会自动下载模型，可能需要一些时间
2. 视频分析是CPU密集型任务，处理大型视频可能需要较长时间
3. 分析准确度取决于视频质量、光线条件和面部朝向 